{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í•œë²ˆì—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 02:23:13,497 - INFO - ğŸŸ¡ [ì§ˆë¬¸ ë¶„ë¥˜] ì…ë ¥ ì§ˆë¬¸: ë°ì´í„° ë¶„ì„ê°€ì™€ ê´€ë ¨ëœ ê³µê³ ê°€ ê¶ê¸ˆí•´\n",
      "2025-03-25 02:23:13,927 - INFO - ğŸŸ¢ [ì§ˆë¬¸ ë¶„ë¥˜ ì™„ë£Œ] ì¹´í…Œê³ ë¦¬: ì±„ìš© ì •ë³´\n",
      "2025-03-25 02:23:13,980 - INFO - ğŸŸ¢ [DB ë°ì´í„° ë¡œë“œ ì™„ë£Œ] ì´ 1267ê°œ ë¬¸ì„œ ê°€ì ¸ì˜´\n",
      "2025-03-25 02:23:14,058 - INFO - ğŸŸ¢ [ë¬¸ì„œ ë³€í™˜ ì™„ë£Œ] ì´ 2108ê°œ ë¬¸ì„œ ìƒì„±ë¨\n",
      "2025-03-25 02:23:14,063 - INFO - ğŸŸ¡ [ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ] ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
      "2025-03-25 02:23:14,089 - INFO - ğŸŸ¢ [ë²¡í„° ìŠ¤í† ì–´ ì¤€ë¹„ ì™„ë£Œ] ë¬¸ì„œ ê°œìˆ˜: 2108\n",
      "2025-03-25 02:23:15,088 - INFO - ìœ ì‚¬ë„ ìµœê³  ì ìˆ˜: 0.3259929418563843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸:\n",
      "        1. ë‹¹ì‹ ì€ ì¡Jobì˜ ì±„ìš© ì „ë¬¸ê°€ì…ë‹ˆë‹¤.ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ëŠ” ì±„ìš© ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.\n",
      "        2. ì±„ìš© ê³µê³ ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí• ì‹œ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. 'ê³µê³ ì œëª©', 'ê³µê³ ë§í¬', 'ê¸°ì—…ëª…'ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”. ê°œìˆ˜ì™€ ê´€ë ¨ëœ ëª…ì‹œê°€ ì—†ì„ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ 3ê°œì˜ ê³µê³ ë¥¼ ì œê³µí•˜ì„¸ìš”.\n",
      "        - ê³µê³  ì œëª©: (ê³µê³ ì œëª©)\n",
      "        - ê³µê³  ë§í¬: (ê³µê³ ë§í¬)\n",
      "        - ê¸°ì—…ëª…:(ê¸°ì—…ëª…)\n",
      "        - íƒœê·¸:(íƒœê·¸)\n",
      "        - ì£¼ìš” ì—…ë¬´: (ì£¼ìš” ì—…ë¬´ì— ëŒ€í•œ ì„¤ëª…)\n",
      "        - ìê²© ìš”ê±´: (í•„ìˆ˜ ìê²© ìš”ê±´)\n",
      "\n",
      "        3. ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì—ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ì±„ìš© ì •ë³´ ì§ˆë¬¸ì„ ìœ ë„í•˜ì„¸ìš”.\n",
      "        4. ì§ê¸‰ê³¼ ê´€ë ¨ëœ ë‹µë³€ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ì§ê¸‰ê³¼ ê´€ë ¨í•œ ì§ˆë¬¸ì—ëŠ” ê³µê³ ë§í¬ë¥¼ ì œê³µí•˜ì„¸ìš”\n",
      "\n",
      "        ì§ˆë¬¸: ë°ì´í„° ë¶„ì„ê°€ì™€ ê´€ë ¨ëœ ê³µê³ ê°€ ê¶ê¸ˆí•´\n",
      "        \n",
      "        ê´€ë ¨ ë¬¸ì„œ:\n",
      "        id: rec-50306090\n",
      "ê¸°ì—…ëª…: (ì£¼)íŠ¸ë¦¬í”Œí•˜ì´ì— \n",
      "ê¸°ì—…ë§í¬: https://www.saramin.co.kr/zf_user/company-info/view-inner-recruit?csn=T1JLcjJQVXVnVzJIK1hrQlBoWmZFZz09\n",
      "ê³µê³ ì œëª©: [ì—°êµ¬ì†Œ] ì˜¨ë¼ì¸ ë§ˆì¼€íŒ… ë°ì´í„° ë¶„ì„ ë° ì„¤ê³„ (ê²½ë ¥)\n",
      "ê³µê³ ë§í¬: https://www.saramin.co.kr/zf_user/jobs/relay/view?view_type=list&rec_idx=50306090\n",
      "íƒœê·¸: ['ë°ì´í„°ë¼ë²¨ë§', 'ë°ì´í„°ë§ˆì´ë‹', 'ë°ì´í„°ì‹œê°í™”', 'ë¨¸ì‹ ëŸ¬ë‹', 'AI(ì¸ê³µì§€ëŠ¥)']\n",
      "ê²½ë ¥: \n",
      "í•™ë ¥: ëŒ€ì¡¸(2,3ë…„ì œ) ì´ìƒ\n",
      "ê·¼ë¬´í˜•íƒœ: ì •ê·œì§ ìˆ˜ìŠµê¸°ê°„ 3ê°œì›”\n",
      "ê¸‰ì—¬: ë©´ì ‘ í›„ ê²°ì •\n",
      "ê·¼ë¬´ì§€ì—­: ì„œìš¸ ê¸ˆì²œêµ¬\n",
      "ì§€ì›ì‹œì‘ì¼: 2025.03.21 17:00\n",
      "ì§€ì›ë§ˆê°ì¼: 2025.04.20 23:59\n",
      "ì§€ì›ë°©ë²•: ì‚¬ëŒì¸ ì…ì‚¬ì§€ì›\n",
      "ì ‘ìˆ˜ì–‘ì‹: ì‚¬ëŒì¸ ì´ë ¥ì„œ ì–‘ì‹\n",
      "ë‹´ë‹¹ì: ì¸ì‚¬íŒ€\n",
      "ì—°ë½ì²˜: \n",
      "refined_content_revised: [ì±„ìš© ê³µê³  ë‚´ìš©]\n",
      "ì±„ìš©ì¸ì›: 0ëª…  \n",
      "ê·¼ë¬´í˜•íƒœ: ì •ê·œì§  \n",
      "ì§ê¸‰:  \n",
      "ê·¼ë¬´ì¼ì‹œ: ì£¼ 5ì¼ ê·¼ë¬´ (í† /ì¼, ê³µíœ´ì¼ íœ´ë¬´)  \n",
      "ê·¼ë¬´ì§€ì—­: ì„œìš¸ì‹œ ê¸ˆì²œêµ¬ ë””ì§€í„¸ë¡œ 121(ì—ì´ìŠ¤ê°€ì‚°íƒ€ì›Œ), 10ì¸µ  \n",
      "ì „í˜•ì ˆì°¨: ê²½ë ¥ ê²€ì¦(ë ˆí¼ëŸ°ìŠ¤ ì²´í¬) ë° ë©´ì ‘ ì „í˜•  \n",
      "ì ‘ìˆ˜ë°©ë²•: í•´ë‹¹ ì‚¬í•­ ì—†ìŒ  \n",
      "\n",
      "[ì±„ìš© ê³µê³  ì£¼ìš” ë‚´ìš©]\n",
      "- ì£¼ìš” ì—…ë¬´: ì˜¨ë¼ì¸ ë§ˆì¼€íŒ… ë°ì´í„° ë¶„ì„ ë° ì„¤ê³„, ë°ì´í„° ë¶„ì„ ì œì•ˆ ê¸°íš, Google Analytics 4 êµ¬ì¶• ë° ë¶„ì„ ì„¤ê³„, ê³ ê° Segmentation ê¸°íš ë° ì„¤ê³„, ML/AI ê´€ë ¨ í†µê³„ ëª¨ë¸ ì—°êµ¬ ë° ì„¤ê³„  \n",
      "- ìê²© ìš”ê±´: Python, javascript, Bigquery ë“± ê¸°ì´ˆì  ê°œë°œ ì–¸ì–´ ì§€ì‹ ë° GCP í™œìš©í•œ ë°ì´í„° ë¶„ì„ ê¸°ì´ˆ ëŠ¥ë ¥ ë³´ìœ , Google Analytics 4 êµ¬ì¶• ë° ë¶„ì„ ê²½í—˜ ë³´ìœ   \n",
      "- ìš°ëŒ€ ì‚¬í•­: ë§ˆì¼€íŒ… ë°ì´í„° ë¶„ì„ ë° ë™ì¢… ë¶„ì•¼ ì—…ë¬´ ê²½í—˜, GCP í™œìš© ê²½í—˜, ML/AI ê´€ë ¨ í”„ë¡œì íŠ¸ ê²½í—˜\n",
      "\n",
      "[ê·¸ ì™¸]\n",
      "- ê·¸ ì™¸ ì •ë³´ :  \n",
      "  1. íšŒì‚¬ ì†Œê°œ  \n",
      "     - 2017ë…„ ì„¤ë¦½, AI ê¸°ë°˜ í”¼ë¶€ ë°ì´í„° ë¶„ì„ ë° ë·°í‹° ì½˜í…ì¸  ì œê³µ ì†”ë£¨ì…˜ ê°œë°œ  \n",
      "     - ì§ì› ìˆ˜ 47ëª…, ì‘ë…„ ë§¤ì¶œ 70ì–µ, 2022ë…„ 200ì–µ íˆ¬ì ìœ ì¹˜  \n",
      "     - ë² íŠ¸ë‚¨ í•˜ë…¸ì´ ì˜ê³¼ëŒ€í•™ ë° ì—°ì„¸ëŒ€ ì„¸ë¸Œë€ìŠ¤ ë³‘ì›ê³¼ ì‚°í•™í˜‘ë™ ì²´ê²°  \n",
      "     - ì‹œì„¸ í™•ì¥ì— ë”°ë¥¸ ì¸ë ¥ ì¶©ì›  \n",
      "  2. ê¸‰ì—¬: 6-8ì²œë§Œì› / ì¸ì„¼í‹°ë¸Œ ë° í‡´ì§ê¸ˆ ë³„ë„  \n",
      "  3. ì ‘ìˆ˜ê¸°ê°„: 2025ë…„ 3ì›” 22ì¼ (í† ) 17ì‹œ ~ ì±„ìš©ì‹œ  \n",
      "  4. ì´ë ¥ì„œ ë° ìê¸°ì†Œê°œì„œ: ì›Œë“œíŒŒì¼ë¡œ ì‘ì„±  \n",
      "  5. ìœ ì˜ì‚¬í•­: ì…ì‚¬ì§€ì› ì„œë¥˜ì— í—ˆìœ„ì‚¬ì‹¤ ë°œê²¬ ì‹œ, ì±„ìš© ì·¨ì†Œ ê°€ëŠ¥.\n",
      "\n",
      "[ì±„ìš© ê³µê³  ì£¼ìš” ë‚´ìš©]  \n",
      "- ì£¼ìš” ì—…ë¬´: KPI ì„¤ì • ë° ê³¼ì œ ê¸°íšÂ·ì¶”ì§„, A/B í…ŒìŠ¤íŠ¸ ìš´ì˜, íŒ€ í˜‘ì—…, ë°ì´í„° ë¶„ì„ ë° ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§, ì‹ ê·œ ê¸°ëŠ¥ ë°œêµ´ ë° ì„±ì¥ ì „ëµ ìˆ˜ë¦½  \n",
      "- ìê²© ìš”ê±´: ë¬¸ì œ í•´ê²° ê²½í—˜, SW ì—”ì§€ë‹ˆì–´ë¡œì„œ MVP ê°œë°œ ê²½í—˜, PO/PM ê²½ë ¥ 2ë…„ ì´ìƒ, ìœ ê´€ ê²½ë ¥ 5ë…„ ì´ìƒ, íŒ€ ë¦¬ë”© ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥, A/B í…ŒìŠ¤íŠ¸ ë° SQL í™œìš© ëŠ¥ë ¥  \n",
      "- ìš°ëŒ€ ì‚¬í•­: ìŠ¤íƒ€íŠ¸ì—… ì°½ì—… ê²½í—˜, LLM ê¸°ë°˜ AI ì œí’ˆÂ·ê¸°ëŠ¥ ê°œë°œ ê²½í—˜, ë§ˆì¼€íŒ…/ê·¸ë¡œìŠ¤ í•´í‚¹ ì‹¤ë¬´ ì´í•´ë„  \n",
      "\n",
      "[ê·¸ ì™¸]  \n",
      "- ê·¸ ì™¸ ì •ë³´:  \n",
      "  - ê¸°ì—…ëª… ë¹„ê³µê°œ ì§„í–‰  \n",
      "  - ê¸‰ì—¬ëŠ” ë©´ì ‘ í›„ í˜‘ì˜  \n",
      "  - ë³µë¦¬í›„ìƒì€ íšŒì‚¬ ë‚´ê·œì— ë”°ë¦„, ë³µì§€ ìš°ìˆ˜  \n",
      "  - ë¬¸ì˜ì‚¬í•­ ì—°ë½ì²˜: 010-2627-3496 (ì±„ìš©ë‹´ë‹¹ì)\n",
      "\n",
      "[ì±„ìš© ê³µê³  ì£¼ìš” ë‚´ìš©]  \n",
      "- ì£¼ìš” ì—…ë¬´: LLMê³¼ GraphRAG í˜¹ì€ RAGê¸°ìˆ ì„ í™œìš©í•˜ì—¬ AI Agent ì†”ë£¨ì…˜ ê°œë°œ, ë°ì´í„° EDA ë° ê°€ê³µ, ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ì§€ì‹ê·¸ë˜í”„ êµ¬ì¶• ë° ê·¸ë˜í”„ì•Œê³ ë¦¬ì¦˜ì„ í†µí•œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ, ML/DLê¸°ìˆ  ì ìš©  \n",
      "- ìê²© ìš”ê±´: ê²½ë ¥ 1ë…„ ~ 20ë…„, Graph Algorithm ë˜ëŠ” Network Science ê¸°ìˆ  ê²½í—˜, SQL ë° Python ëŠ¥ìˆ™, LLMê³¼ Graph RAG ê¸°ìˆ ì— ëŒ€í•œ ê´€ì‹¬ ë° ê²½í—˜, ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ (ìì‹ ì˜ ìƒê°ì„ ê³µìœ í•˜ë©° ì£¼ë„ì ìœ¼ë¡œ ì—…ë¬´ ìˆ˜í–‰)  \n",
      "- ìš°ëŒ€ ì‚¬í•­: ê´€ë ¨ ê²½ë ¥ 3ë…„ ì´ìƒ, Knowledge Graph ì„¤ê³„ ë˜ëŠ” êµ¬ì¶• ê²½í—˜, GraphDB í™œìš© ê²½í—˜, ê´€ë ¨ ì „ê³µ ì„?ë°•ì‚¬ í•™ìœ„ ì†Œì§€ì, ê·¸ë˜í”„ ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„ ë° ì ìš© ê²½í—˜  \n",
      "\n",
      "[ê·¸ ì™¸]  \n",
      "- ê·¸ ì™¸ ì •ë³´: ì±„ìš© ê¸°ì—…ì€ ì½”ìŠ¤ë‹¥ ìƒì¥ê¸°ì—…ì´ë©° AI ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ë° íŒë§¤ ì—…ì¢…ì— ì†í•¨. ì—°ë´‰ì€ ì œí•œì´ ì—†ìŒ. ì œì¶œì„œë¥˜ëŠ” êµ­ë¬¸ ì´ë ¥ì„œë¡œ, ì‚¬ëŒì´ ì•„ë‹Œ ì§ì ‘ ì‘ì„±ëœ ê²½ë ¥ ì¤‘ì‹¬ ì´ë ¥ì„œì—¬ì•¼ í•¨.\n",
      "        \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 02:23:26,391 - INFO - ğŸŸ¢ [ë‹µë³€ ê²€ì¦ ì™„ë£Œ] ê²°ê³¼: ì¼ì¹˜\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¤ìŒì€ ë°ì´í„° ë¶„ì„ê°€ì™€ ê´€ë ¨ëœ ì±„ìš© ê³µê³ ì…ë‹ˆë‹¤.\n",
      "\n",
      "1. \n",
      "   - ê³µê³  ì œëª©: [ì—°êµ¬ì†Œ] ì˜¨ë¼ì¸ ë§ˆì¼€íŒ… ë°ì´í„° ë¶„ì„ ë° ì„¤ê³„ (ê²½ë ¥)\n",
      "   - ê³µê³  ë§í¬: [ë§í¬](https://www.saramin.co.kr/zf_user/jobs/relay/view?view_type=list&rec_idx=50306090)\n",
      "   - ê¸°ì—…ëª…: (ì£¼)íŠ¸ë¦¬í”Œí•˜ì´ì— \n",
      "   - íƒœê·¸: ['ë°ì´í„°ë¼ë²¨ë§', 'ë°ì´í„°ë§ˆì´ë‹', 'ë°ì´í„°ì‹œê°í™”', 'ë¨¸ì‹ ëŸ¬ë‹', 'AI(ì¸ê³µì§€ëŠ¥)']\n",
      "   - ì£¼ìš” ì—…ë¬´: ì˜¨ë¼ì¸ ë§ˆì¼€íŒ… ë°ì´í„° ë¶„ì„ ë° ì„¤ê³„, ë°ì´í„° ë¶„ì„ ì œì•ˆ ê¸°íš, Google Analytics 4 êµ¬ì¶• ë° ë¶„ì„ ì„¤ê³„, ê³ ê° Segmentation ê¸°íš ë° ì„¤ê³„, ML/AI ê´€ë ¨ í†µê³„ ëª¨ë¸ ì—°êµ¬ ë° ì„¤ê³„\n",
      "   - ìê²© ìš”ê±´: Python, javascript, Bigquery ë“± ê¸°ì´ˆì  ê°œë°œ ì–¸ì–´ ì§€ì‹ ë° GCP í™œìš©í•œ ë°ì´í„° ë¶„ì„ ê¸°ì´ˆ ëŠ¥ë ¥ ë³´ìœ , Google Analytics 4 êµ¬ì¶• ë° ë¶„ì„ ê²½í—˜ ë³´ìœ \n",
      "\n",
      "2. \n",
      "   - ê³µê³  ì œëª©: ë°ì´í„° ë¶„ì„ ë° AI Agent ì†”ë£¨ì…˜ ê°œë°œ\n",
      "   - ê³µê³  ë§í¬: [ë§í¬](https://www.example.com)  *(ê°€ìƒì˜ ë§í¬ì…ë‹ˆë‹¤)*\n",
      "   - ê¸°ì—…ëª…: ë¹„ê³µì‹ ê¸°ì—…ëª…\n",
      "   - íƒœê·¸: ['AI', 'ë°ì´í„°ë¶„ì„', 'ML', 'DL']\n",
      "   - ì£¼ìš” ì—…ë¬´: LLMê³¼ GraphRAG í˜¹ì€ RAGê¸°ìˆ ì„ í™œìš©í•˜ì—¬ AI Agent ì†”ë£¨ì…˜ ê°œë°œ, ë°ì´í„° EDA ë° ê°€ê³µ, ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ì§€ì‹ê·¸ë˜í”„ êµ¬ì¶• ë° ê·¸ë˜í”„ì•Œê³ ë¦¬ì¦˜ì„ í†µí•œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ, ML/DLê¸°ìˆ  ì ìš©\n",
      "   - ìê²© ìš”ê±´: ê²½ë ¥ 1ë…„ ~ 20ë…„, Graph Algorithm ë˜ëŠ” Network Science ê¸°ìˆ  ê²½í—˜, SQL ë° Python ëŠ¥ìˆ™, LLMê³¼ Graph RAG ê¸°ìˆ ì— ëŒ€í•œ ê´€ì‹¬ ë° ê²½í—˜\n",
      "\n",
      "3. \n",
      "   - ê³µê³  ì œëª©: KPI ì„¤ì • ë° ë°ì´í„° ë¶„ì„\n",
      "   - ê³µê³  ë§í¬: [ë§í¬](https://www.example.com)  *(ê°€ìƒì˜ ë§í¬ì…ë‹ˆë‹¤)*\n",
      "   - ê¸°ì—…ëª…: ë¹„ê³µì‹ ê¸°ì—…ëª…\n",
      "   - íƒœê·¸: ['ë°ì´í„°ë¶„ì„', 'KPI', 'A/B í…ŒìŠ¤íŠ¸']\n",
      "   - ì£¼ìš” ì—…ë¬´: KPI ì„¤ì • ë° ê³¼ì œ ê¸°íšÂ·ì¶”ì§„, A/B í…ŒìŠ¤íŠ¸ ìš´ì˜, íŒ€ í˜‘ì—…, ë°ì´í„° ë¶„ì„ ë° ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§, ì‹ ê·œ ê¸°ëŠ¥ ë°œêµ´ ë° ì„±ì¥ ì „ëµ ìˆ˜ë¦½\n",
      "   - ìê²© ìš”ê±´: ë¬¸ì œ í•´ê²° ê²½í—˜, SW ì—”ì§€ë‹ˆì–´ë¡œì„œ MVP ê°œë°œ ê²½í—˜, PO/PM ê²½ë ¥ 2ë…„ ì´ìƒ, ìœ ê´€ ê²½ë ¥ 5ë…„ ì´ìƒ, íŒ€ ë¦¬ë”© ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥, A/B í…ŒìŠ¤íŠ¸ ë° SQL í™œìš© ëŠ¥ë ¥\n",
      "\n",
      "ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”? ë‹¤ë¥¸ ì±„ìš© ì •ë³´ë„ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import pymysql\n",
    "import locale\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# ë¡œê·¸ ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API ì„¤ì •\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# âœ… 1ï¸âƒ£ ì§ˆë¬¸ ë¶„ë¥˜ GPT\n",
    "def classify_question(question):\n",
    "    \"\"\"ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì¹´í…Œê³ ë¦¬ë¥¼ ë°˜í™˜í•˜ëŠ” GPT\"\"\"\n",
    "    logging.info(f\"ğŸŸ¡ [ì§ˆë¬¸ ë¶„ë¥˜] ì…ë ¥ ì§ˆë¬¸: {question}\")\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ëŠ” AIì…ë‹ˆë‹¤.\n",
    "    \n",
    "    ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬:\n",
    "    1. ì±„ìš© ì •ë³´\n",
    "    2. ì¼ë°˜ ì§ˆë¬¸\n",
    "    \n",
    "    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— 'ìš”ì²­'ì´ í¬í•¨ë˜ì§€ ì•Šì•˜ì„ì‹œ ì¼ë°˜ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.\n",
    "    ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "    **ì¶œë ¥ í˜•ì‹ (JSON)**\n",
    "    {\"category\": \"ì±„ìš© ì •ë³´\"}\n",
    "    \"\"\"\n",
    "\n",
    "    ####ì‚¬ëŒë“¤ì˜ ë¡œê·¸ë°ì´í„° ë¶„ì„ì„ í†µí•´ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„¸ë¶„í™” í•˜ê² ë‹¤~. ë°°íƒ€ì ì´ì—¬ì•¼í•¨.\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=50\n",
    "    )\n",
    "\n",
    "    result = json.loads(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    logging.info(f\"ğŸŸ¢ [ì§ˆë¬¸ ë¶„ë¥˜ ì™„ë£Œ] ì¹´í…Œê³ ë¦¬: {result['category']}\")\n",
    "    return result  # JSON ë³€í™˜\n",
    "\n",
    "# âœ… 2ï¸âƒ£ ë°ì´í„° ê²€ìƒ‰ GPT\n",
    "def connect_to_db():\n",
    "    \"\"\"MySQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°\"\"\"\n",
    "    return pymysql.connect(\n",
    "        host='127.0.0.1',\n",
    "        port=3306,\n",
    "        user='root',\n",
    "        passwd='seul0899',\n",
    "        db='saramin',\n",
    "        charset=\"utf8mb4\"\n",
    "    )\n",
    "\n",
    "def fetch_from_saramin_refined():\n",
    "    \"\"\"MySQLì—ì„œ ì±„ìš© ì •ë³´ë¥¼ ê°€ì ¸ì˜´\"\"\"\n",
    "    connection = connect_to_db()\n",
    "    cursor = connection.cursor(pymysql.cursors.DictCursor)\n",
    "    cursor.execute(\"SELECT * FROM saramin_5_combined_revised_fordb\")\n",
    "    fetch_result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    \n",
    "    logging.info(f\"ğŸŸ¢ [DB ë°ì´í„° ë¡œë“œ ì™„ë£Œ] ì´ {len(fetch_result)}ê°œ ë¬¸ì„œ ê°€ì ¸ì˜´\")\n",
    "    return fetch_result\n",
    "\n",
    "def chunk_document(doc_text, chunk_size=1000, chunk_overlap=100):\n",
    "    \"\"\"ë¬¸ì„œë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• \"\"\"\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return text_splitter.split_text(doc_text)\n",
    "\n",
    "def convert_to_documents(courses):\n",
    "    \"\"\"MySQL ë°ì´í„°ë¥¼ LangChain ë¬¸ì„œë¡œ ë³€í™˜\"\"\"\n",
    "    documents = []\n",
    "    for course in courses:\n",
    "        doc_text = \"\\n\".join([f\"{key}: {value}\" for key, value in course.items()])\n",
    "        chunks = chunk_document(doc_text)\n",
    "        documents.extend([Document(page_content=chunk) for chunk in chunks])\n",
    "\n",
    "    logging.info(f\"ğŸŸ¢ [ë¬¸ì„œ ë³€í™˜ ì™„ë£Œ] ì´ {len(documents)}ê°œ ë¬¸ì„œ ìƒì„±ë¨\")\n",
    "    return documents\n",
    "\n",
    "def create_vector_store(documents):\n",
    "    \"\"\"ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•˜ì—¬ ì €ì¥\"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    faiss_path = './db/faiss'  # ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ\n",
    "\n",
    "    # âœ… ë²¡í„° ìŠ¤í† ì–´ê°€ ì¡´ì¬í•˜ë©´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    if os.path.exists(faiss_path):\n",
    "        logging.info(\"ğŸŸ¡ [ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ] ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\")\n",
    "        store = FAISS.load_local(faiss_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "        # âŒ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œ ìƒì„± í›„ ì €ì¥\n",
    "        logging.info(\"ğŸ”µ [ë²¡í„° ìŠ¤í† ì–´ ìƒì„±] ìƒˆë¡œìš´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë§Œë“­ë‹ˆë‹¤.\")\n",
    "        store = FAISS.from_documents(documents, embeddings)\n",
    "        store.save_local(faiss_path)  # ë²¡í„° ìŠ¤í† ì–´ ì €ì¥\n",
    "        logging.info(\"ğŸŸ¢ [ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ] ìƒˆë¡œìš´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    logging.info(f\"ğŸŸ¢ [ë²¡í„° ìŠ¤í† ì–´ ì¤€ë¹„ ì™„ë£Œ] ë¬¸ì„œ ê°œìˆ˜: {len(documents)}\")\n",
    "    return store\n",
    "\n",
    "def create_chatbot(vector_store):\n",
    "    \"\"\"ì±„ìš© ì •ë³´ ê¸°ë°˜ ì±—ë´‡ ìƒì„±\"\"\"\n",
    "    chat_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"question\", \"context\"],  # í•„ìš”í•œ ë³€ìˆ˜ ì •ì˜\n",
    "        template=\"\"\"\n",
    "        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸:\n",
    "        1. ë‹¹ì‹ ì€ ì¡Jobì˜ ì±„ìš© ì „ë¬¸ê°€ì…ë‹ˆë‹¤.ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ëŠ” ì±„ìš© ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.\n",
    "        2. ì±„ìš© ê³µê³ ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí• ì‹œ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. 'ê³µê³ ì œëª©', 'ê³µê³ ë§í¬', 'ê¸°ì—…ëª…'ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”. ê°œìˆ˜ì™€ ê´€ë ¨ëœ ëª…ì‹œê°€ ì—†ì„ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ 3ê°œì˜ ê³µê³ ë¥¼ ì œê³µí•˜ì„¸ìš”.\n",
    "        - ê³µê³  ì œëª©: (ê³µê³ ì œëª©)\n",
    "        - ê³µê³  ë§í¬: (ê³µê³ ë§í¬)\n",
    "        - ê¸°ì—…ëª…:(ê¸°ì—…ëª…)\n",
    "        - íƒœê·¸:(íƒœê·¸)\n",
    "        - ì£¼ìš” ì—…ë¬´: (ì£¼ìš” ì—…ë¬´ì— ëŒ€í•œ ì„¤ëª…)\n",
    "        - ìê²© ìš”ê±´: (í•„ìˆ˜ ìê²© ìš”ê±´)\n",
    "\n",
    "        3. ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì—ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ì±„ìš© ì •ë³´ ì§ˆë¬¸ì„ ìœ ë„í•˜ì„¸ìš”.\n",
    "        4. ì§ê¸‰ê³¼ ê´€ë ¨ëœ ë‹µë³€ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ì§ê¸‰ê³¼ ê´€ë ¨í•œ ì§ˆë¬¸ì—ëŠ” ê³µê³ ë§í¬ë¥¼ ì œê³µí•˜ì„¸ìš”\n",
    "\n",
    "        ì§ˆë¬¸: {question}\n",
    "        \n",
    "        ê´€ë ¨ ë¬¸ì„œ:\n",
    "        {context}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    return ConversationalRetrievalChain.from_llm(\n",
    "        llm=chat_model,\n",
    "        retriever=vector_store.as_retriever(),\n",
    "        return_source_documents=True,\n",
    "        verbose=True,\n",
    "        combine_docs_chain_kwargs={\"prompt\": prompt_template}  # ì´ì œ PromptTemplate ê°ì²´ ì‚¬ìš©\n",
    "    )\n",
    "\n",
    "def get_answer(question, retrieval_chain):\n",
    "    \"\"\"ì±„ìš© ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì‘ë‹µ ìƒì„±\"\"\"\n",
    "    result = retrieval_chain.invoke({\"question\": question, \"chat_history\": []})\n",
    "\n",
    "    answer = result.get(\"answer\", \"\")\n",
    "    logging.info(f\"ğŸŸ¢ [ë‹µë³€ ìƒì„± ì™„ë£Œ] ë‹µë³€: {answer[:100]}...\")  # ë„ˆë¬´ ê¸¸ë©´ ìë¦„\n",
    "\n",
    "    return answer, result.get(\"source_documents\", [])\n",
    "\n",
    "# âœ… 3ï¸âƒ£ ì§ˆë¬¸-ë‹µë³€ ê²€ì¦ GPT\n",
    "def verify_answer(question, answer):\n",
    "    \"\"\"ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ë…¼ë¦¬ì ìœ¼ë¡œ ë§ëŠ”ì§€ ê²€ì¦\"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    ë‹¹ì‹ ì€ AI ê²€ì¦ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.\n",
    "\n",
    "    - ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ë§ìœ¼ë©´: {\"verification\": \"ì¼ì¹˜\"}\n",
    "    - ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ë§ì§€ ì•Šìœ¼ë©´: {\"verification\": \"ë¶ˆì¼ì¹˜\"}\n",
    "    \"\"\"\n",
    "    ### ë¶ˆì¼ì¹˜ í•˜ëŠ” ê³¼ì •ì„ í™•ì¸. ë¶ˆì¼ì¹˜ ë¹„ìœ¨ ê²€ì¦. \n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"ì§ˆë¬¸: {question}\\në‹µë³€: {answer}\"}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=50\n",
    "    )\n",
    "\n",
    "    result = json.loads(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    logging.info(f\"ğŸŸ¢ [ë‹µë³€ ê²€ì¦ ì™„ë£Œ] ê²°ê³¼: {result['verification']}\")\n",
    "    return result\n",
    "\n",
    "# âœ… ëŒ€í™” ê¸°ë¡ ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸\n",
    "chat_history = []\n",
    "\n",
    "def get_answer_with_similarity_check(question, vector_store, chat_history):\n",
    "    \"\"\"ì±„ìš© ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ë©°, ìœ ì‚¬ë„ê°€ 0.2 ì´ìƒì¸ì§€ í™•ì¸\"\"\"\n",
    "    retriever = vector_store.as_retriever()\n",
    "    \n",
    "    # ìœ ì‚¬ë„ ê²€ì‚¬ (ìµœëŒ€ 3ê°œì˜ ë¬¸ì„œ ê²€ìƒ‰)\n",
    "    docs_with_scores = retriever.vectorstore.similarity_search_with_score(question, k=3)\n",
    "    \n",
    "    # ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ë¬¸ì„œ ì°¾ê¸°\n",
    "    if not docs_with_scores:\n",
    "        logging.warning(\"âŒ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        return \"âš  ê´€ë ¨ëœ ì±„ìš© ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.\", []\n",
    "    \n",
    "    highest_score = max(score for _, score in docs_with_scores)\n",
    "    logging.info(f'âœ…ìœ ì‚¬ë„ ìµœê³  ì ìˆ˜: {highest_score}')\n",
    "\n",
    "    # âœ… ìœ ì‚¬ë„ê°€ 0.3 ì´ìƒì´ë©´ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„±\n",
    "    if highest_score >= 0.3:\n",
    "        retrieval_chain = create_chatbot(vector_store)\n",
    "        result = retrieval_chain.invoke({\n",
    "            \"question\": question, \n",
    "            \"chat_history\": chat_history  # âœ… ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶”ê°€\n",
    "        })\n",
    "        answer = result.get(\"answer\", \"\")\n",
    "\n",
    "        # âœ… ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸\n",
    "        chat_history.append({\"question\": question, \"answer\": answer})\n",
    "        \n",
    "        return answer, result.get(\"source_documents\", [])\n",
    "\n",
    "    # âŒ ìœ ì‚¬ë„ê°€ ë‚®ì„ ê²½ìš° ë‹¤ì‹œ ì§ˆë¬¸ì„ ìœ ë„\n",
    "    logging.warning(\"âŒ ìœ ì‚¬ë„ê°€ ë‚®ì•„ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    return \"âš  í˜„ì¬ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì±„ìš© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ë” ìƒì„¸íˆ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!\", []\n",
    "\n",
    "\n",
    "# âœ… 4ï¸âƒ£ ì „ì²´ ì‹¤í–‰ í•¨ìˆ˜ (ëŒ€í™” ê¸°ë¡ í™œìš©)\n",
    "def handle_request(question):\n",
    "    \"\"\"ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³ , ìœ ì‚¬ë„ ê¸°ì¤€ì„ ì ìš©í•˜ì—¬ ë°ì´í„° ê²€ìƒ‰\"\"\"\n",
    "    \n",
    "    # 1ï¸âƒ£ ì§ˆë¬¸ ë¶„ë¥˜ ì‹¤í–‰\n",
    "    category_result = classify_question(question)\n",
    "    category = category_result[\"category\"]\n",
    "    \n",
    "    if category == \"ì¼ë°˜ ì§ˆë¬¸\":\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\",\n",
    "                \"content\": \"\"\"ë‹¹ì‹ ì€ ì¡Jobì˜ ì±„ìš© ì „ë¬¸ê°€ì…ë‹ˆë‹¤. \n",
    "                            ë‹¹ì‹ ì€ ì±„ìš© ì •ë³´ì— ê´€í•œ ì§ˆë¬¸ì—ë§Œ ëŒ€ë‹µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ ì™¸ì˜ ì§ˆë¬¸ì—ëŠ” í•œì¤„ì˜ ë‹¨ë‹µí˜•ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n",
    "                            'ì±„ìš© ê³µê³ ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”?'ë¥¼ ë§ˆì§€ë§‰ì— ë§ë¶™ì´ì„¸ìš”\"\"\"},\n",
    "                # âœ… ëŒ€í™” ê¸°ë¡ ì¶”ê°€\n",
    "                *[\n",
    "                    {\"role\": \"user\", \"content\": entry[\"question\"]}\n",
    "                    for entry in chat_history\n",
    "                ],\n",
    "                *[\n",
    "                    {\"role\": \"assistant\", \"content\": entry[\"answer\"]}\n",
    "                    for entry in chat_history\n",
    "                ],\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        \n",
    "        answer = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "        # âœ… ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸\n",
    "        chat_history.append({\"question\": question, \"answer\": answer})\n",
    "        \n",
    "        return answer\n",
    "\n",
    "    # 2ï¸âƒ£ ì±„ìš© ì •ë³´ ê²€ìƒ‰ ì‹¤í–‰\n",
    "    courses = fetch_from_saramin_refined()\n",
    "    documents = convert_to_documents(courses)\n",
    "    vector_store = create_vector_store(documents)\n",
    "\n",
    "    # 2ï¸âƒ£.5ï¸âƒ£ ìœ ì‚¬ë„ ê²€ì‚¬ ë° ì‘ë‹µ ìƒì„± (ëŒ€í™” ê¸°ë¡ ì¶”ê°€)\n",
    "    answer, source_docs = get_answer_with_similarity_check(question, vector_store, chat_history)\n",
    "\n",
    "    # 3ï¸âƒ£ ì§ˆë¬¸-ë‹µë³€ ê²€ì¦ ì‹¤í–‰ (ìœ ì‚¬ë„ ê¸°ì¤€ í†µê³¼í•œ ê²½ìš°ë§Œ ê²€ì¦)\n",
    "    if source_docs:\n",
    "        verification_result = verify_answer(question, answer)\n",
    "        if verification_result[\"verification\"] == \"ì¼ì¹˜\":\n",
    "            return answer  \n",
    "        else:\n",
    "        # ê²€ì¦ì´ ì‹¤íŒ¨í–ˆì„ ê²½ìš° ì‚¬ìš©ìì—ê²Œ ë‹¤ì‹œ ì§ˆë¬¸ì„ ìœ ë„í•˜ëŠ” ë©”ì‹œì§€ ë°˜í™˜\n",
    "            return \"ë‹µë³€ì´ ì •í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.\"\n",
    "        \n",
    "\n",
    "    return answer  # ìœ ì‚¬ë„ ë‚®ì„ ê²½ìš° ì§ˆë¬¸ ìœ ë„ ë©”ì‹œì§€ ë°˜í™˜\n",
    "\n",
    "# âœ… ì‹¤í–‰ ì˜ˆì œ\n",
    "if __name__ == \"__main__\":\n",
    "    test_question = \"ë°ì´í„° ë¶„ì„ê°€ì™€ ê´€ë ¨ëœ ê³µê³ ê°€ ê¶ê¸ˆí•´\" \n",
    "    print(handle_request(test_question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-hGK6LnUe-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
